{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVu3JJSRhc6n"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Setup (no tensorflow_addons needed) ---\n",
        "import os, random, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from tensorflow.keras import layers as L, Model\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "SEED = 13\n",
        "tf.random.set_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 2\n",
        "CLASS_NAMES = ['O', 'R']  # adjust to your folder names if needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl1GB3dJktMQ",
        "outputId": "a6a61d43-9aa8-4059-a22d-977cb3ed5df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'waste-classification-data' dataset.\n",
            "Path to dataset files: /kaggle/input/waste-classification-data\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"techsash/waste-classification-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcTEVH4-GvHT",
        "outputId": "19f0bc21-743f-4256-acb0-8599dccfdb37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGEuWGyDmkH2",
        "outputId": "55a99575-3eb0-4be5-92ea-d3496693e32c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 22564 files [03:04, 122.33 files/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split complete: 80% train, 20% val. Data saved to /content/Split\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "import os\n",
        "\n",
        "# Path to your dataset\n",
        "base_path = os.path.join(path, \"DATASET\")\n",
        "\n",
        "# Define the output directory for the split data in a writable location\n",
        "output_dir = \"/content/Split\"\n",
        "\n",
        "# Split the TRAIN folder into train/val\n",
        "splitfolders.ratio(\n",
        "    input=os.path.join(base_path, \"TRAIN\"),\n",
        "    output=output_dir,  # New folder for the split, changed to a writable path\n",
        "    seed=42,\n",
        "    ratio=(0.8, 0.2),  # 80% train, 20% val\n",
        "    group_prefix=None\n",
        ")\n",
        "\n",
        "print(f\"Split complete: 80% train, 20% val. Data saved to {output_dir}\")\n",
        "\n",
        "# Update train_dir and val_dir to reflect the new output location\n",
        "train_dir = os.path.join(output_dir, \"train\")\n",
        "val_dir = os.path.join(output_dir, \"val\")\n",
        "test_dir  = os.path.join(base_path, \"TEST\")   # untouched holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnVLXmOdnPFE",
        "outputId": "8a5bb703-64ed-47ce-f6fe-572ebb14a1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18051 files belonging to 2 classes.\n",
            "Found 4513 files belonging to 2 classes.\n",
            "Found 2513 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf, numpy as np, os\n",
        "from collections import Counter\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "SEED = 42\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 2 # Ensure this is correctly set if not already\n",
        "\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED, shuffle=True\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED, shuffle=False\n",
        ")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = preprocess_input(image)\n",
        "    label = tf.one_hot(label, NUM_CLASSES) # One-hot encode labels\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "test_ds = test_ds.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7UrtcO_uERv",
        "outputId": "35b8ad80-50fb-4a92-cefa-8df8be362176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: {np.int64(0): 10052, np.int64(1): 7999}\n",
            "Class weights: {0: 0.8978810187027457, 1: 1.1283285410676334}\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Extract labels from the training dataset and convert them to integer class labels\n",
        "train_labels = np.concatenate([np.argmax(y, axis=1) for x, y in train_ds], axis=0)\n",
        "# val_labels = np.concatenate([np.argmax(y, axis=1) for x, y in val_ds], axis=0)\n",
        "\n",
        "cw = Counter(train_labels)\n",
        "total = sum(cw.values())\n",
        "class_weight = {i: total/(NUM_CLASSES*cw[i]) for i in range(NUM_CLASSES)}\n",
        "print(\"Class counts:\", dict(cw))\n",
        "print(\"Class weights:\", class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7scdIw4-uf--"
      },
      "outputs": [],
      "source": [
        "data_augment = tf.keras.Sequential([\n",
        "    L.RandomFlip(\"horizontal\"),\n",
        "    L.RandomRotation(0.08),   # ~±4.5 degrees\n",
        "    L.RandomZoom(0.1),\n",
        "    L.RandomContrast(0.1),\n",
        "], name=\"augment\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "rvjT_mYZukT9",
        "outputId": "20f776b2-cfc0-4cb7-fcde-f502a601716b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m2,562\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,052,133\u001b[0m (15.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,133</span> (15.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,010,110\u001b[0m (15.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,010,110</span> (15.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,023\u001b[0m (164.16 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,023</span> (164.16 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# --- Model: EfficientNetB0 + dropout ---\n",
        "base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE+(3,))\n",
        "\n",
        "inp = L.Input(shape=IMG_SIZE+(3,))\n",
        "x = data_augment(inp)                      # augmentation inside the model\n",
        "x = base(x, training=False)                # make sure BN runs in inference mode when frozen\n",
        "x = L.GlobalAveragePooling2D()(x)\n",
        "x = L.Dropout(0.25)(x)\n",
        "#out = L.Dense(1, activation=\"sigmoid\")(x)\n",
        "#model = Model(inp, out)\n",
        "\n",
        "out = L.Dense(2, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "metrics = [\"accuracy\"]\n",
        "if NUM_CLASSES == 2:\n",
        "  metrics.append(tf.keras.metrics.AUC(name='pr_auc', curve='PR'))\n",
        "\n",
        "model = Model(inp, out)\n",
        "model.compile(optimizer=Adam(1e-3), loss=loss, metrics=metrics)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I5upaKQG27d",
        "outputId": "6caec715-ade5-454d-c005-d414729f759e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "Epoch 1/3\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5543s\u001b[0m 10s/step - accuracy: 0.9015 - auc: 0.9604 - f1_score: 0.9015 - loss: 0.2570 - pr_auc: 0.9581 - precision: 0.9015 - recall: 0.9015 - val_accuracy: 0.9169 - val_auc: 0.9706 - val_f1_score: 0.9169 - val_loss: 0.2221 - val_pr_auc: 0.9685 - val_precision: 0.9169 - val_recall: 0.9169\n",
            "Epoch 2/3\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6949s\u001b[0m 12s/step - accuracy: 0.9282 - auc: 0.9768 - f1_score: 0.9282 - loss: 0.1922 - pr_auc: 0.9755 - precision: 0.9282 - recall: 0.9282 - val_accuracy: 0.9207 - val_auc: 0.9687 - val_f1_score: 0.9207 - val_loss: 0.2379 - val_pr_auc: 0.9655 - val_precision: 0.9207 - val_recall: 0.9207\n",
            "Epoch 3/3\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6665s\u001b[0m 12s/step - accuracy: 0.9348 - auc: 0.9808 - f1_score: 0.9348 - loss: 0.1719 - pr_auc: 0.9793 - precision: 0.9348 - recall: 0.9348 - val_accuracy: 0.9446 - val_auc: 0.9861 - val_f1_score: 0.9446 - val_loss: 0.1510 - val_pr_auc: 0.9857 - val_precision: 0.9446 - val_recall: 0.9446\n"
          ]
        }
      ],
      "source": [
        "# Cell: compile & fit (REPLACE WHOLE CELL)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Custom F1 metric class\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# --- compile ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), # Changed to CategoricalCrossentropy\n",
        "    metrics = [\n",
        "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "        tf.keras.metrics.AUC(name=\"auc\"),                 # ROC-AUC\n",
        "        tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),  # Precision–Recall AUC\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\"),\n",
        "        F1Score(name=\"f1_score\")\n",
        "    ]\n",
        "    # run_eagerly=False by default; keep for performance\n",
        ")\n",
        "\n",
        "# --- Explicitly call predict once to build the model's prediction graph before training ---\n",
        "# Using a small batch of dummy data to trace the model's prediction graph\n",
        "if isinstance(val_ds, tf.data.Dataset):\n",
        "    for x_batch, _ in val_ds.take(1):\n",
        "        _ = model.predict(x_batch)\n",
        "else:\n",
        "    _ = model.predict(next(iter(val_ds))[0])\n",
        "\n",
        "\n",
        "# --- train ---\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    callbacks=[]\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}