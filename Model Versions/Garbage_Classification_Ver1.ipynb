{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUPGFNQSSHtB"
      },
      "source": [
        "Version 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gaIXZ0xGSAMs"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Setup (no tensorflow_addons needed) ---\n",
        "import os, random, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from tensorflow.keras import layers as L, Model\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "SEED = 13\n",
        "tf.random.set_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 2\n",
        "CLASS_NAMES = ['O', 'R']  # adjust to your folder names if needed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"techsash/waste-classification-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwhT2UIshznv",
        "outputId": "9c56ec72-096a-46f1-efed-3045deadb588"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/techsash/waste-classification-data?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 427M/427M [00:03<00:00, 120MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/techsash/waste-classification-data/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y38LNOc9ST87",
        "outputId": "c87f5d69-4baa-466e-9b4b-1c71c10e1d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: /root/.cache/kagglehub/datasets/techsash/waste-classification-data/versions/1/DATASET/TRAIN \n",
            "Val/Test: /root/.cache/kagglehub/datasets/techsash/waste-classification-data/versions/1/DATASET/TEST\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Paths (adjust if needed) ---\n",
        "# Assuming the dataset is structured as: path/DATASET/TRAIN and path/DATASET/TEST\n",
        "data_root = os.path.join(path, \"DATASET\") # Adjust this if the actual structure is different\n",
        "train_dir = os.path.join(data_root, \"TRAIN\")\n",
        "val_dir   = os.path.join(data_root, \"TEST\")   # Using TEST as validation/test split for convenience\n",
        "test_dir  = val_dir\n",
        "\n",
        "for p in [train_dir, val_dir]:\n",
        "    if not os.path.isdir(p):\n",
        "        raise FileNotFoundError(f\"Directory not found: {p}\")\n",
        "print(\"Train:\", train_dir, \"\\nVal/Test:\", val_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Dataset loader using tf.data ---\n",
        "def decode_img(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE, antialias=True)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = preprocess_input(img)  # EfficientNet scaling\n",
        "    return img, label\n",
        "\n",
        "def build_paths_labels(root):\n",
        "    paths, labels = [], []\n",
        "    for idx, cname in enumerate(CLASS_NAMES):\n",
        "        cdir = os.path.join(root, cname)\n",
        "        if not os.path.isdir(cdir):\n",
        "            cdir2 = os.path.join(root, cname.lower())\n",
        "            cdir = cdir2 if os.path.isdir(cdir2) else cdir\n",
        "        for r, _, files in os.walk(cdir):\n",
        "            for f in files:\n",
        "                if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                    paths.append(os.path.join(r, f))\n",
        "                    labels.append(idx)\n",
        "    return paths, labels\n",
        "\n",
        "train_paths, train_labels = build_paths_labels(train_dir)\n",
        "val_paths,   val_labels   = build_paths_labels(val_dir)\n",
        "print(f\"Train images: {len(train_paths)}  |  Val images: {len(val_paths)}\")\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "val_ds   = tf.data.Dataset.from_tensor_slices((val_paths,   val_labels))\n",
        "\n",
        "train_ds = (train_ds\n",
        "            .shuffle(8192, seed=SEED, reshuffle_each_iteration=True)\n",
        "            .map(decode_img, num_parallel_calls=AUTOTUNE)\n",
        "            .batch(BATCH_SIZE)\n",
        "            .prefetch(AUTOTUNE))\n",
        "\n",
        "val_ds = (val_ds\n",
        "          .map(decode_img, num_parallel_calls=AUTOTUNE)\n",
        "          .batch(BATCH_SIZE)\n",
        "          .prefetch(AUTOTUNE))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt5cCR4-iK0u",
        "outputId": "41bbf9ed-af45-412f-a1df-b75b38a89994"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 22564  |  Val images: 2513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Optional: class weights (helpful if imbalance) ---\n",
        "from collections import Counter\n",
        "cw = Counter(train_labels)\n",
        "total = sum(cw.values())\n",
        "class_weight = {i: total/(NUM_CLASSES*cw[i]) for i in range(NUM_CLASSES)}\n",
        "print(\"Class counts:\", dict(cw))\n",
        "print(\"Class weights:\", class_weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9RqND7_vYDA",
        "outputId": "b8dd2fb5-e6af-4467-f167-91731c2ac800"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts: {0: 12565, 1: 9999}\n",
            "Class weights: {0: 0.8978909669717469, 1: 1.1283128312831283}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Data augmentation block using Keras preprocessing layers ---\n",
        "# These run on GPU and don't require addons.\n",
        "data_augment = tf.keras.Sequential([\n",
        "    L.RandomFlip(\"horizontal\"),\n",
        "    L.RandomRotation(0.08),   # ~±4.5 degrees\n",
        "    L.RandomZoom(0.1),\n",
        "    L.RandomContrast(0.1),\n",
        "], name=\"augment\")\n"
      ],
      "metadata": {
        "id": "0DGNUqXdvnta"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Model: EfficientNetB0 + dropout ---\n",
        "base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE+(3,))\n",
        "\n",
        "inp = L.Input(shape=IMG_SIZE+(3,))\n",
        "x = data_augment(inp)                      # augmentation inside the model\n",
        "x = base(x, training=False)                # make sure BN runs in inference mode when frozen\n",
        "x = L.GlobalAveragePooling2D()(x)\n",
        "x = L.Dropout(0.25)(x)\n",
        "out = L.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = Model(inp, out)\n",
        "\n",
        "# Phase 1: freeze backbone\n",
        "for l in base.layers:\n",
        "    l.trainable = False\n",
        "\n",
        "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05)\n",
        "opt = Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=opt, loss=loss,\n",
        "              metrics=[\n",
        "                  tf.keras.metrics.BinaryAccuracy(name=\"acc\"),\n",
        "                  tf.keras.metrics.AUC(name=\"auc\")\n",
        "              ])\n",
        "\n",
        "ckpt = ModelCheckpoint(\"best_freeze.keras\", monitor=\"val_auc\", mode=\"max\", save_best_only=True, verbose=1)\n",
        "es   = EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=4, restore_best_weights=True)\n",
        "rlr  = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=2, verbose=1)\n",
        "\n",
        "hist1 = model.fit(train_ds, validation_data=val_ds, epochs=8,\n",
        "                  callbacks=[ckpt, es, rlr], class_weight=class_weight)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gi58rNXvqIm",
        "outputId": "ddc9109e-846e-4743-ae6d-0be8420b0f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/8\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.9399 - auc: 0.7631 - loss: 0.2444\n",
            "Epoch 1: val_auc improved from -inf to 0.98176, saving model to best_freeze.keras\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2079s\u001b[0m 3s/step - acc: 0.9399 - auc: 0.7635 - loss: 0.2444 - val_acc: 0.9343 - val_auc: 0.9818 - val_loss: 0.2567 - learning_rate: 0.0010\n",
            "Epoch 2/8\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.9516 - auc: 0.7907 - loss: 0.2149\n",
            "Epoch 2: val_auc improved from 0.98176 to 0.98612, saving model to best_freeze.keras\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2082s\u001b[0m 3s/step - acc: 0.9516 - auc: 0.7910 - loss: 0.2149 - val_acc: 0.9399 - val_auc: 0.9861 - val_loss: 0.2539 - learning_rate: 0.0010\n",
            "Epoch 3/8\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.9611 - auc: 0.7929 - loss: 0.1997\n",
            "Epoch 3: val_auc did not improve from 0.98612\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2088s\u001b[0m 3s/step - acc: 0.9611 - auc: 0.7932 - loss: 0.1998 - val_acc: 0.9455 - val_auc: 0.9852 - val_loss: 0.2453 - learning_rate: 0.0010\n",
            "Epoch 4/8\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.9602 - auc: 0.7903 - loss: 0.2031\n",
            "Epoch 4: val_auc improved from 0.98612 to 0.98625, saving model to best_freeze.keras\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2062s\u001b[0m 3s/step - acc: 0.9602 - auc: 0.7905 - loss: 0.2032 - val_acc: 0.9447 - val_auc: 0.9863 - val_loss: 0.2492 - learning_rate: 0.0010\n",
            "Epoch 5/8\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - acc: 0.9592 - auc: 0.7930 - loss: 0.2023\n",
            "Epoch 5: val_auc did not improve from 0.98625\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "\u001b[1m706/706\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2029s\u001b[0m 3s/step - acc: 0.9592 - auc: 0.7933 - loss: 0.2023 - val_acc: 0.9443 - val_auc: 0.9845 - val_loss: 0.2495 - learning_rate: 0.0010\n",
            "Epoch 6/8\n",
            "\u001b[1m 94/706\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26:54\u001b[0m 3s/step - acc: 0.9151 - auc: 0.0000e+00 - loss: 0.2568"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}