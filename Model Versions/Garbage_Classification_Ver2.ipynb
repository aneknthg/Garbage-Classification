{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVu3JJSRhc6n"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.0' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- Setup (no tensorflow_addons needed) ---\n",
        "import os, random, math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
        "from tensorflow.keras import layers as L, Model\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "SEED = 13\n",
        "tf.random.set_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 2\n",
        "CLASS_NAMES = ['O', 'R']  # adjust to your folder names if needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl1GB3dJktMQ"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"techsash/waste-classification-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGEuWGyDmkH2",
        "outputId": "a827c422-9047-41cc-d182-7fc46acf6dab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 22564 files [00:28, 788.91 files/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split complete: 80% train, 20% val. Data saved to /content/Split\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import splitfolders\n",
        "import os\n",
        "\n",
        "# Path to your dataset\n",
        "base_path = os.path.join(path, \"DATASET\")\n",
        "\n",
        "# Define the output directory for the split data in a writable location\n",
        "output_dir = \"/content/Split\"\n",
        "\n",
        "# Split the TRAIN folder into train/val\n",
        "splitfolders.ratio(\n",
        "    input=os.path.join(base_path, \"TRAIN\"),\n",
        "    output=output_dir,  # New folder for the split, changed to a writable path\n",
        "    seed=42,\n",
        "    ratio=(0.8, 0.2),  # 80% train, 20% val\n",
        "    group_prefix=None\n",
        ")\n",
        "\n",
        "print(f\"Split complete: 80% train, 20% val. Data saved to {output_dir}\")\n",
        "\n",
        "# Update train_dir and val_dir to reflect the new output location\n",
        "train_dir = os.path.join(output_dir, \"train\")\n",
        "val_dir = os.path.join(output_dir, \"val\")\n",
        "test_dir  = os.path.join(base_path, \"TEST\")   # untouched holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnVLXmOdnPFE",
        "outputId": "b3c52410-9f4d-48c0-add2-d1676e0d91e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 18051 files belonging to 2 classes.\n",
            "Found 4513 files belonging to 2 classes.\n",
            "Found 2513 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf, numpy as np, os\n",
        "from collections import Counter\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "SEED = 42\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 2 # Ensure this is correctly set if not already\n",
        "\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED, shuffle=True\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED, shuffle=False\n",
        ")\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    test_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False\n",
        ")\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = preprocess_input(image)\n",
        "    label = tf.one_hot(label, NUM_CLASSES) # One-hot encode labels\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "test_ds = test_ds.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7UrtcO_uERv",
        "outputId": "62ae0e5e-a41b-43d1-c7cb-4ed3290835a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class counts: {np.int64(0): 2513, np.int64(1): 2000}\n",
            "Class weights: {0: 0.8979307600477517, 1: 1.12825}\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Extract labels from the training dataset and convert them to integer class labels\n",
        "train_labels = np.concatenate([np.argmax(y, axis=1) for x, y in train_ds], axis=0)\n",
        "# val_labels = np.concatenate([np.argmax(y, axis=1) for x, y in val_ds], axis=0)\n",
        "\n",
        "cw = Counter(train_labels)\n",
        "total = sum(cw.values())\n",
        "class_weight = {i: total/(NUM_CLASSES*cw[i]) for i in range(NUM_CLASSES)}\n",
        "print(\"Class counts:\", dict(cw))\n",
        "print(\"Class weights:\", class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7scdIw4-uf--"
      },
      "outputs": [],
      "source": [
        "data_augment = tf.keras.Sequential([\n",
        "    L.RandomFlip(\"horizontal\"),\n",
        "    L.RandomRotation(0.08),   # ~±4.5 degrees\n",
        "    L.RandomZoom(0.1),\n",
        "    L.RandomContrast(0.1),\n",
        "], name=\"augment\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "rvjT_mYZukT9",
        "outputId": "8841b18d-1eb8-486b-9b0f-eb33d805711c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ augment (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m2,562\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,133</span> (15.46 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,052,133\u001b[0m (15.46 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,010,110</span> (15.30 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,010,110\u001b[0m (15.30 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">42,023</span> (164.16 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m42,023\u001b[0m (164.16 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# --- Model: EfficientNetB0 + dropout ---\n",
        "base = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE+(3,))\n",
        "\n",
        "inp = L.Input(shape=IMG_SIZE+(3,))\n",
        "x = data_augment(inp)                      # augmentation inside the model\n",
        "x = base(x, training=False)                # make sure BN runs in inference mode when frozen\n",
        "x = L.GlobalAveragePooling2D()(x)\n",
        "x = L.Dropout(0.25)(x)\n",
        "#out = L.Dense(1, activation=\"sigmoid\")(x)\n",
        "#model = Model(inp, out)\n",
        "\n",
        "out = L.Dense(2, activation=\"softmax\", dtype=\"float32\")(x)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "metrics = [\"accuracy\"]\n",
        "if NUM_CLASSES == 2:\n",
        "  metrics.append(tf.keras.metrics.AUC(name='pr_auc', curve='PR'))\n",
        "\n",
        "model = Model(inp, out)\n",
        "model.compile(optimizer=Adam(1e-3), loss=loss, metrics=metrics)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saskfNDPFPWV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "ckpt = ModelCheckpoint(\"best_head.keras\", monitor=\"val_pr_auc\" if NUM_CLASSES==2 else \"val_accuracy\",\n",
        "                       mode=\"max\", save_best_only=True, verbose=1)\n",
        "es   = EarlyStopping(monitor=\"val_pr_auc\" if NUM_CLASSES==2 else \"val_accuracy\",\n",
        "                     mode=\"max\", patience=5, restore_best_weights=True, verbose=1)\n",
        "rlr  = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=2, verbose=1)\n",
        "\n",
        "class F1BestThreshold(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, val_data):\n",
        "        super().__init__()\n",
        "        self.val_data = val_data\n",
        "        self.best_f1, self.best_thresh = -1, 0.5\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if NUM_CLASSES != 2: return\n",
        "        y_true_list, y_prob_list = [], []\n",
        "        for xb, yb in self.val_data:\n",
        "            y_true_list.append(tf.argmax(yb, axis=1).numpy()) # Adjust for one-hot encoded labels\n",
        "            # For softmax output with 2 classes, get probability of the positive class (index 1)\n",
        "            y_prob_list.append(self.model.predict(xb, verbose=0)[:, 1])\n",
        "\n",
        "        y_true = np.concatenate(y_true_list)\n",
        "        y_prob = np.concatenate(y_prob_list)\n",
        "\n",
        "        thr_list = np.linspace(0.1, 0.9, 33)\n",
        "        best, best_t = -1, 0.5\n",
        "        for t in thr_list:\n",
        "            f1 = f1_score(y_true, (y_prob >= t).astype(int))\n",
        "            if f1 > best: best, best_t = f1, t\n",
        "        self.best_f1, self.best_thresh = best, best_t\n",
        "        print(f\"\\n[Val] F1={best:.4f} at thresh={best_t:.2f}\")\n",
        "\n",
        "f1_cb = F1BestThreshold(val_ds) if NUM_CLASSES==2 else None\n",
        "cbs = [ckpt, es, rlr] + ([f1_cb] if f1_cb else [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I5upaKQG27d",
        "outputId": "1e61ff8d-9b8b-43f3-cbf5-507f30cd0466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "Epoch 1/3\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.8915 - auc: 0.9555 - f1_score: 0.8915 - loss: 0.2659 - pr_auc: 0.9544 - precision: 0.8915 - recall: 0.8915\n",
            "[Val] F1=0.9083 at thresh=0.80\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5803s\u001b[0m 10s/step - accuracy: 0.8915 - auc: 0.9556 - f1_score: 0.8915 - loss: 0.2659 - pr_auc: 0.9544 - precision: 0.8915 - recall: 0.8915 - val_accuracy: 0.8967 - val_auc: 0.9520 - val_f1_score: 0.8967 - val_loss: 0.3312 - val_pr_auc: 0.9456 - val_precision: 0.8967 - val_recall: 0.8967\n",
            "Epoch 2/3\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9192 - auc: 0.9722 - f1_score: 0.9192 - loss: 0.2101 - pr_auc: 0.9717 - precision: 0.9192 - recall: 0.9192\n",
            "[Val] F1=0.9083 at thresh=0.65\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5815s\u001b[0m 10s/step - accuracy: 0.9193 - auc: 0.9722 - f1_score: 0.9193 - loss: 0.2101 - pr_auc: 0.9717 - precision: 0.9193 - recall: 0.9193 - val_accuracy: 0.9052 - val_auc: 0.9658 - val_f1_score: 0.9052 - val_loss: 0.2426 - val_pr_auc: 0.9656 - val_precision: 0.9052 - val_recall: 0.9052\n",
            "Epoch 3/3\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9352 - auc: 0.9809 - f1_score: 0.9352 - loss: 0.1730 - pr_auc: 0.9805 - precision: 0.9352 - recall: 0.9352\n",
            "[Val] F1=0.9379 at thresh=0.72\n",
            "\u001b[1m565/565\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5829s\u001b[0m 10s/step - accuracy: 0.9352 - auc: 0.9809 - f1_score: 0.9352 - loss: 0.1730 - pr_auc: 0.9805 - precision: 0.9352 - recall: 0.9352 - val_accuracy: 0.9304 - val_auc: 0.9816 - val_f1_score: 0.9304 - val_loss: 0.1758 - val_pr_auc: 0.9811 - val_precision: 0.9304 - val_recall: 0.9304\n"
          ]
        }
      ],
      "source": [
        "# Cell: compile & fit (REPLACE WHOLE CELL)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Custom F1 metric class\n",
        "class F1Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = tf.keras.metrics.Precision()\n",
        "        self.recall = tf.keras.metrics.Recall()\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    def result(self):\n",
        "        p = self.precision.result()\n",
        "        r = self.recall.result()\n",
        "        return 2 * ((p * r) / (p + r + K.epsilon()))\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# --- compile ---\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False), # Changed to CategoricalCrossentropy\n",
        "    metrics = [\n",
        "        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "        tf.keras.metrics.AUC(name=\"auc\"),                 # ROC-AUC\n",
        "        tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),  # Precision–Recall AUC\n",
        "        tf.keras.metrics.Precision(name=\"precision\"),\n",
        "        tf.keras.metrics.Recall(name=\"recall\"),\n",
        "        F1Score(name=\"f1_score\")\n",
        "    ]\n",
        "    # run_eagerly=False by default; keep for performance\n",
        ")\n",
        "\n",
        "# --- callbacks ---\n",
        "cb = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_pr_auc\", patience=5, mode=\"max\", restore_best_weights=True),\n",
        "    F1BestThreshold(val_data=val_ds)\n",
        "]\n",
        "\n",
        "# --- Explicitly call predict once to build the model's prediction graph before training ---\n",
        "# Using a small batch of dummy data to trace the model's prediction graph\n",
        "if isinstance(val_ds, tf.data.Dataset):\n",
        "    for x_batch, _ in val_ds.take(1):\n",
        "        _ = model.predict(x_batch)\n",
        "else:\n",
        "    _ = model.predict(next(iter(val_ds))[0])\n",
        "\n",
        "\n",
        "# --- train ---\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=3,\n",
        "    callbacks=cb\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVg-iFPMLhcF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
